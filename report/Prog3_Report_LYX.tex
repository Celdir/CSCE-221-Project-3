%% LyX 2.1.4 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass{article}
\usepackage[latin9]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\begin{document}

\title{\textbf{Programming 2 Assignment}}


\author{Michael Earl, Gerald Hu \\
 \\
 CSCE 221-200}


\date{April 11, 2016}

\maketitle

\section*{Introduction}

\noindent The purpose of this assignment was to analyze the theoretical
and actual performance of several common sorting algorithms discussed
in class. The project implemented bubble sort, two ``slow sorting''
algorithms (insertion and selection sort), and two ``fast sorting''
algorithms (mergesort and quicksort). The running time of these algorithms
was analyzed for several types of data: sorted data, reverse-sorted
data, randomized data, and data with many similar elements. \\



\section*{Implementation Details}

\noindent All sorting algorithms took random-access iterators to the
first and last elements of the container, and a comparator. \\


\noindent Bubble Sort is a simple sorting algorithm. It compares a
set of two elements that are next to each other, and if the elements
in the bubble are out of order, they are swapped. This set traverses
the entire container from start to end, then starts from the beginning
again, repeating until there are no more swaps to make.\\


\noindent Selection Sort is one of the two ``slow'' sorting algorithms.
It traverses the entire container searching for the smallest element,
then swaps that element into the first position. Then it searches
the remainder of the container for the next-smallest element, then
swaps that element into the first position of the remainder. On its
$i$th traversal, it will swap the smallest element into the $i$th
position. This process continues $n$ times, at which point there
is no more ''remainder'' of the container to traverse.\\


\noindent Insertion Sort is the other of the two ``slow'' sorting
algorithms. It traverses the entire container $n$ times. In each
traversal, for each step $i$, if $i$ is not the first element, and
if $i$ and $i-1$ are out of order, the two are swapped, swapping
the element into an ''already-sorted'' portion of the container.
Each traversal will grow the already-sorted portion, until all the
data is in the sorted portion. \\


\noindent Mergesort is one of the two ``fast'' sorting algorithms.
It splits the input data into two subarrays, and recursively splits
each of those subarrays into two subarrays, repeating the splitting
process until each subarray is of size$<$2. These subarrays are then
sorted in sets of two, and the resulting sorted data is put into an
array and returned. The returned sorted data is merged with more data
using the same merge function, until fully-sorted data is returned.\\


\noindent Quicksort is the other of the two ``fast'' sorting algorithms.
It randomly selects an element of the data to use as a ``pivot''
, and traverses the entire container. It moves all elements less than
the pivot to before the pivot's position, and moves all elements greater
than the pivot to after the pivot's position, all of which is done
in-place. This places the pivot in the proper position. Then, quicksort
is recursively called, once on the set of elements less than the pivot,
and once on the set of elements greater than the pivot. \\


\noindent The skeleton of timing.cpp was provided by the instructors.
The timing function was already implemented for randomly sorted input
data; we modified it to analyze sorted and reverse-sorted data, as
well as data with many similar elements. The timing function relies
on high\_resolution\_clock; given a sorting function and a number
$n$, the timing function would generate a vector with $n$ elements
in it. Then, the timing function would try to sort the vector using
the specified sorting algorithm. This process was repeated for increasing
sizes of $n$, and repeated 10 times at each $n$ to ensure an accurate
average time.\\



\section*{Theoretical Analysis}

\noindent Bubble Sort is $O(n^{2})$ average and worst case. It will
force the largest element to the end after $n$ comparisons; then
it will repeat this for the $n-1$ smallest element, then the $n-2$
smallest element, and so on, repeating $n$ times in total. $n$ traversals
and $n$ comparisons/swaps at each traversal results in $O(n^{2})$
time. Bubble Sort's best case is $O(n)$ in the case that it's already
sorted. It traverses the list once and makes $n$ comparisons, but
does not do any swaps or any further traversals.\\


\noindent Selection Sort is $O(n^{2})$ in all cases. In searching
for the smallest element, it will traverse $n$ elements and make
$n$ comparisons, before forcing the smallest element to the start.
It then repeats this process for a sublist of size $n-1$, then $n-2$...$n-n$.
$\sum_{i=0}^{n}i=(i)(i+1)/2$, which is $O(n^{2})$ behavior. Furthermore,
it will always search for the smallest element, regardless of whether
it needs to be swapped or not, and will perform all traversals.\\


\noindent Insertion Sort is $O(oooooo)$ average and worst case.\\



\section*{Experimental Setup}

Timing tests were conducted using the provided timing.cpp, compiled
with the provided makefile's commands. Compilation was done on the
``linux.cse.tamu.edu'' server, with G++ version 4.7.3 (SUSE Linux)
(found via g++ --version). Compilation was set to the C++11 standard,
with the -G flag enabled and O2 optimization level, warnings set to
-Wall -Werror (warn all and all warnings treated as compilation errors),
and dependencies flagged with -MMD (auto-generate dependencies).\\


\noindent Tests were run on the ``compute.cse.tamu.edu'' server,
which runs Arch Linux x86\_64 version 8.12 (found via arch --version
and lsb\_release -a). This server has 99026668 total kilobytes of
RAM (found via free). It uses Intel Core i7-3970X CPUs (2 sockets,
8 cores per socket, 2 threads per core), with a clock speed of 2000
mHz (found via lscpu). Each core has a Xeon E5-2650 processor (found
via lshw --short).\\


\noindent Timing functions output timing results for input sizes that
were powers of 2, starting from 2 itself, and ending at a maximum
size specified by the user. Each step of the timing was repeated 10
times, and the average of each result taken. Linear height n inserts
went up to a maximum input size of 32768; logarithmic height n inserts
went up to a maximum input size of 4194304, and random n inserts went
up to a maximum input size of 1048576.\\


\noindent timing.o was run twice: first on a tree with AVL rebalancing
and then on a simpler binary tree with no rebalancing method. These
results for the performance were then compared between the two trees.


\section*{Results and Discussion}

In testing the timing performance of the functions for the binary
search tree and AVL tree implementations of the map ADT, only the
insert function was tested. As was discussed in the theoretical analysis
section, all of the three main functions of the map ADT (find, insert,
snd erase) for the binary search tree and AVL tree have the same asymptotic
running time. As a result it is only necessary to test one of the
functions because the results should be asymptotically the same for
the other two as well. \\


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Linear_Time_Per_(Binary)}
\caption{Graph of the Time Taken per Addition for Different Input Sizes for
a Linear Order Added Binary Search Tree}
\label{fig:Linear_Time_Per_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Linear_Time_Per_(AVL)}
\caption{Graph of the Time Taken for Different Input Sizes for a Linear Order
Added AVL Tree}
\label{fig:Linear_Time_Per_AVL} 
\end{figure}


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Linear_Big_O_(Binary)}
\caption{Graph of the Big O Constants for Different Input Sizes for a Linear
Order Added Binary Search Tree}
\label{fig:Linear_Big_O_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Linear_Big_O_(AVL)}
\caption{Graph of the Big O Constants for Different Input Sizes for a Linear
Order Added AVL Tree}
\label{fig:Linear_Big_O_AVL} 
\end{figure}


\noindent The first set of timing tests that was run on the code was
for linearly inserted elements. This means that if the structure of
the tree not changed by rebalancing, the tree would have a height
that is $O(n)$, where $n$ is the number of nodes in the tree. These
tests should result in the worst case for the insertions. This test
was first run on the normal binary search tree, then on the AVL tree.
As predicted by the theoretical analysis, the time taken by the normal
binary search tree was $O(n)$ (because $h$ is $O(n)$). This is
seen in Figure~\ref{fig:Linear_Time_Per_Binary}, where the time
per one insertion goes up basically linearly with respect to the input
size. In contrast, the AVL tree runs in $O(\log{n})$ time, as is
clearly seen in the logarithmic shape of the graph in Figure~\ref{fig:Linear_Time_Per_AVL}.
\\


\noindent The Big O constants were calculated for both types of trees.
They were calculated by dividing the time per insertion by the expected
time for each insertion, which is $n$ for the regular binary search
tree and $\log{n}$ for the AVL tree. The graphs of both of these
results (Figures~\ref{fig:Linear_Big_O_Binary} and~\ref{fig:Linear_Big_O_AVL})
flatten out for their larger input sizes, suggesting that the flattened
value is the Big O constant. The Big O constant for the binary search
tree was $1*10^{-8}$ , and the constant for the AVL tree was $5*10^{-8}$.
The Big O constant is actually larger for the AVL tree than for the
binary search tree. This is inconsequential, however, because their
Big O functions are not the same. Comparing Big O constants is only
meaningful when the functions are the same. In this case, for larger
input values (i.e. asymptotically) the binary search tree will be
much slower because $O(n)$ is much larger than $O(\log{n})$.\\


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Logarithmic_Time_Per_(Binary)}
\caption{Graph of the Time Taken per Addition for Different Input Sizes for
a Logarithmic Order Added Binary Search Tree}
\label{fig:Logarithmic_Time_Per_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Logarithmic_Time_Per_(AVL)}
\caption{Graph of the Time Taken for Different Input Sizes for a Logarithmic
Order Added AVL Tree}
\label{fig:Logarithmic_Time_Per_AVL} 
\end{figure}


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Logarithmic_Big_O_(Binary)}
\caption{Graph of the Big O Constants for Different Input Sizes for a Logarithmic
Order Added Binary Search Tree}
\label{fig:Logarithmic_Big_O_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Logarithmic_Big_O_(AVL)}
\caption{Graph of the Big O Constants for Different Input Sizes for a Logarithmic
Order Added AVL Tree}
\label{fig:Logarithmic_Big_O_AVL} 
\end{figure}


\noindent The next set of tests used logarithmically inserted elements,
meaning that the structure of the tree would be logarithmic if it
was not changed by rebalancing. These tests should yield the best
case for the insertions. Like the last tests, these tests were run
on the binary search tree first, then on the AVL tree. Again, the
results agreed with the theoretical predictions made earlier. The
time taken per insertion with respect to input size for the binary
search tree was $O(\log{n})$ this time, as is seen in Figure~\ref{fig:Logarithmic_Time_Per_Binary}.
This is still $O(h)$; but $h$ is now $O(\log{n})$, instead of $O(n)$
as it was in the last case. Also, as was expected, the results for
the AVL tree were $O(\log{n})$ (Figure~\ref{fig:Logarithmic_Time_Per_AVL}).
\\


\noindent The agreement between the theoretical and actual results
was further confirmed when looking at the Big O constants for the
logarithmic insertions. In this case, the expected time for insertion
for both the binary search tree and the AVL tree were $\log{n}$.
For both tree types, the results for the Big O constants flattened
out for larger input sizes (Figures~\ref{fig:Logarithmic_Big_O_Binary}
and~\ref{fig:Logarithmic_Big_O_AVL}), suggesting that the constants
are correct, as are the Big O functions. The Big O constant appears
to be about $4*10^{-8}$ for the binary search tree and $4*10^{-8}$
for the AVL tree as well. These constants can be compared this time
because the Big O functions are the same ($O(\log{n})$). In this
case they have approximately the same constant, meaning that they
should take approximately the same amount of time. This is significant
because it shows that the overhead for the checks in restructuring
are not significant. The time actually taken for restructures cannot
be determined because they were not needed for this tree shape, but
the checks still occurred and had no discernible impact on the Big
O constant. \\


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Random_Time_Per_(Binary)}
\caption{Graph of the Time Taken per Addition for Different Input Sizes for
a Random Order Added Binary Search Tree}
\label{fig:Random_Time_Per_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Random_Time_Per_(AVL)}
\caption{Graph of the Time Taken for Different Input Sizes for a Random Order
Added AVL Tree}
\label{fig:Random_Time_Per_AVL} 
\end{figure}


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Random_Big_O_(Binary)}
\caption{Graph of the Big O Constants for Different Input Sizes for a Random
Order Added Binary Search Tree}
\label{fig:Random_Big_O_Binary} 
\end{figure}


\begin{figure}[h]
\includegraphics[bb=0 0 200 100,draft,width=11cm,type=eps,type=eps]{report/Random_Big_O_(AVL)}
\caption{Graph of the Big O Constants for Different Input Sizes for a Random
Order Added AVL Tree}
\label{fig:Random_Big_O_AVL} 
\end{figure}


\noindent The last tests that were run were intended to test the average
case for the insertion. This case was the randomly inserted case where
elements were put in the tree in no particular order. The shape of
this tree before restructuring could be anywhere between logarithmic
and linear. The test were run for both the binary search tree and
the AVL tree. \\


\noindent The results for both types of trees were what was predicted.
The results for the time taken per insertion for a binary search tree
were $O(\log{n})$ as can be seen in the graph in Figure~\ref{fig:Random_Time_Per_Binary}.
Since on average the height of a binary search tree will be $O(\log{n})$,
$O(h)=O(\log{n})$, so the results agree with the predictions. The
results for the AVL tree (Figure~\ref{fig:Random_Time_Per_AVL})
show that the insertion for the AVL tree with random trees is also
$O(\log{n})$. This agrees with the theoretical analysis that operations
on the AVL tree are always $O(\log{n})$. \\


\noindent The Big O constants were calculated for both the binary
search tree and the AVL tree. The function that they were both compared
to was $\log{n}$. The graphs of the Big O constants ((Figures~\ref{fig:Random_Big_O_Binary}
and~\ref{fig:Random_Big_O_AVL}) basically flattened out, showing
that the correct Big O function was chosen. The graphs do not quite
flatten out, possibly because the randomness of the inputs was not
quite normalized by the input size. The Big O constant for the binary
search tree was about $9*10^{-8}$ while the constant for the AVL
tree was about $6*10^{-8}$. Since both functions are $O(\log{n})$,
their Big O constants can be compared. The fact that the constant
for the AVL tree is smaller than that of the binary search tree shows
that the AVL tree is better on average. The cost that AVL trees take
in restructuring the elements is less than the cost that the binary
search tree takes in having taller trees. \\


\noindent When comparing the performance of the insertion for either
the binary search tree or the AVL tree, the worst and best cases can
be determined. The results show that the worst, best, and average
cases are what they were expected to be. For the binary search tree,
the linear case was obviously the worst case because it was $O(n)$
while the other two cases were $O(\log{n})$. Looking at the remaining
cases, logarithmic is the best case because it has a Big O constant
of $4*10^{-8}$ while the random case has a Big O constant of $9*10^{-8}$.
The same order holds for the AVL tree. Since its insertions were all
$O(\log{n})$, the cases can be ordered solely by Big O constants.
Since the linear case has fewer inputs, it is important to measure
the Big O constants around the highest input size that the linear
case received, 16384. The Big O constants for the linear, logarithmic,
and random cases around that point are $5.0*10^{-8}$, $2.5*10^{-8}$,
and $4*10^{-8}$, respectively. That means that the best case is the
logarithmic case and the worst case is the linear case, as was expected.


\section*{Conclusion}

This assignment achieved a few main goals. First and foremost, it
deepened our understanding of the way maps and binary search trees
work. It also introduced, in a practical way, how to use AVL trees.
And it verified the theoretical discussions held in class about the
performance of functions of the ADT implementation. The advantages
of the AVL tree were concretely seen in the performance difference
between the regular binary search tree and the AVL tree. From the
timing results obtained in this assignment, it can be seen that AVL
trees are better than or on par with binary search trees in every
situation. Overall, this assignment as a whole gave needed practice
in coding as well as reinforced concepts that were learned in class. 
\end{document}
